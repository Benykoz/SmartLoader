total timesteps,ent_coef_loss,policy_loss,current_lr,entropy,qf1_loss,time_elapsed,ent_coef,n_updates,fps,qf2_loss,mean 100 episode reward,value_loss,episodes
18006,-16.101986,748.97186,0.0002,15.079126,936.35516,45,1.9077625,3752,392,936.68835,-596.9,81.152756,4
42014,-41.501717,2093.0825,0.0002,14.9206,3.541133,87,5.4804335,9752,482,3.490665,-458.8,750.1548,8
66022,-71.01364,6539.532,0.0002,14.775013,207.81349,128,18.201668,15756,513,232.12021,-390.2,8389.396,12
90030,-101.76457,21371.027,0.0002,14.830081,6798.7515,170,60.341743,21756,529,2187.9119,-358.2,82752.22,16
114038,-130.94096,70021.84,0.0002,14.781982,1909.1627,211,200.3548,27760,539,2042.8574,-339.7,809944.25,20
